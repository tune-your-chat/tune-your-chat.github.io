<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="twitter:widgets:csp" content="on" />
    <meta http-equiv="x-ua-compatible" content="ie=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@matrixdotorg" />
    <meta name="twitter:creator" content="@matrixdotorg" />
    
    <meta property="og:url" content="https:&#x2F;&#x2F;tune-your-chat.github.io&#x2F;author&#x2F;denise-almeida&#x2F;" />
    
    
    
    
    <meta property="og:title" content="Matrix.org" />
    
    
    
    <meta property="og:description" content="Matrix, the open protocol for secure decentralised communications" />
    <meta name="description" content="Matrix, the open protocol for secure decentralised communications" />
    
    <meta property="og:image" content="https://matrix.org/blog/img/matrix-logo.png" />
    <meta name="twitter:image" content="https://matrix.org/blog/img/matrix-logo.png" />
    
    <title>Matrix.org - Denise Almeida</title>
    <link rel="shortcut icon" href="/assets/favicon.ico" />
    <link rel="icon" type="image/svg+xml" href="/assets/favicon.svg" />
    <link rel="stylesheet" href=https://tune-your-chat.github.io/style.css?h=0d1a23c06b707a231261 />
    <script async src=https://tune-your-chat.github.io/js/components.js?h=ae3cb894d00e16ef08be></script>
    <script defer data-domain="matrix.org" src="https://plausible.io/js/script.tagged-events.js"></script>


    
<link rel="alternate" type="application/rss+xml" title="RSS" href="https://tune-your-chat.github.io/author/denise-almeida/atom.xml">
</head>

<body>
    
    <header class="site-header">
    <a href="/" class="brand">
        <img src="/images/matrix-logo-white.svg" alt="Matrix logo">
    </a>
    <input id="site-header-dropdown-checkbox" type="checkbox" class="dropdown-checkbox" aria-hidden="true">
    <label for="site-header-dropdown-checkbox" class="dropdown-button">&#xe602;</label>
    <label for="site-header-dropdown-checkbox" class="page-overlay"></label>
    <nav>
        
        
        <a href="https:&#x2F;&#x2F;spec.matrix.org" class="
            ">
            Spec
        </a>
        
        
        
        
        
        <div class="section-wrap">
            <input id="foundation-submenu-checkbox" type="checkbox" class="submenu-checkbox" aria-hidden="true"
                >
            <label for="foundation-submenu-checkbox" class="submenu-title">Foundation <div class="arrow">
                </div></label>

            <div class="section-submenu-wrap">
                <div class="section-submenu">
                    
                    
                    <a href="&#x2F;foundation&#x2F;about&#x2F;">About Matrix</a>
                    
                    <a href="&#x2F;foundation&#x2F;governing-board-elections&#x2F;">Governing Board Elections 2024</a>
                    
                </div>
            </div>
        </div>
        
        
        
        <a href="&#x2F;blog&#x2F;" class="
            ">
            Blog
        </a>
        
        
        
        <a href="&#x2F;docs&#x2F;" class="
            ">
            Docs
        </a>
        
        
        
        
        
        <div class="section-wrap">
            <input id="ecosystem-submenu-checkbox" type="checkbox" class="submenu-checkbox" aria-hidden="true"
                >
            <label for="ecosystem-submenu-checkbox" class="submenu-title">Ecosystem <div class="arrow">
                </div></label>

            <div class="section-submenu-wrap">
                <div class="section-submenu">
                    
                    
                    <a href="&#x2F;ecosystem&#x2F;clients&#x2F;">Clients</a>
                    
                    
                    <a href="&#x2F;ecosystem&#x2F;bridges&#x2F;">Bridges</a>
                    
                    
                    <a href="&#x2F;ecosystem&#x2F;servers&#x2F;">Servers</a>
                    
                    <a href="&#x2F;ecosystem&#x2F;tune&#x2F;">Tune Your Chat</a>
                    
                    <a href="&#x2F;ecosystem&#x2F;integrations&#x2F;">Integrations</a>
                    
                    <a href="&#x2F;ecosystem&#x2F;sdks&#x2F;">SDKs</a>
                    
                    <a href="&#x2F;ecosystem&#x2F;hosting&#x2F;">Hosting</a>
                    
                </div>
            </div>
        </div>
        
        
        
        <a href="&#x2F;support" class="
            ">
            Donate
        </a>
        
        
        
        <a href="&#x2F;try-matrix&#x2F;" class="primary
            ">
            Try Matrix
        </a>
        
        
    </nav>
</header>


    <main>
        
<div id="taxonomy-single">
    <div class="content">
        <header>
            <h1>Denise Almeida</h1>
            3 posts tagged with "Denise Almeida" <a href="/author">(See all Author)</a>
            
        </header>

        
        <article class="post">
            <header>
                <h2><a href="https:&#x2F;&#x2F;tune-your-chat.github.io&#x2F;blog&#x2F;2024&#x2F;06&#x2F;regulatory-update&#x2F;" title="Policy and regulation update 2024: Matrix and the GDPR">Policy and regulation update 2024: Matrix and the GDPR</a></h2>
                <span>
                    06.06.2024 07:00
                    —
                    <a href="/category/foundation">
                        Foundation
                    </a>
                    —
                    <a
                        href="/author/denise-almeida">
                        Denise Almeida
                    </a>
                </span>
                
            </header>
            <div>
                
                <p>If you have been following the matrix.org blog for some time, you will know that we’ve never been ones to shy away from complex topics like public policy and its impacts on Matrix. With this blog post series, our aim is to introduce a more regular cadence to our regulatory updates and to be more transparent about where we are focusing our efforts in this area.</p>
<p>Each blog post in the series will focus on a given theme or piece of law, as well as its relevant jurisdiction. We will start this series by taking a deep dive into EU regulation, starting with the General Data Protection Regulation (GDPR). Future blog posts in the series will cover the digital services package (DMA and DSA), the incoming CRA and the highly controversial CSAM regulation. These will be followed by a series dedicated to the UK, particularly UK applications of European law such as the GDPR and ePrivacy directive, as well as the Online Safety Act and the IPA amendment bill. Finally, we will conclude the series by looking across the pond and diving into the Cloud Act, as well as KOSA and other existing proposals.</p>

                <p><a href="/blog/2024/06/regulatory-update/#continue-reading">Continue reading…</a></p>
                
            </div>
        </article>
        
        <article class="post">
            <header>
                <h2><a href="https:&#x2F;&#x2F;tune-your-chat.github.io&#x2F;blog&#x2F;2024&#x2F;01&#x2F;open-letter-csa&#x2F;" title="Open letter to EU Member States on the proposed CSA Regulation">Open letter to EU Member States on the proposed CSA Regulation</a></h2>
                <span>
                    22.01.2024 00:00
                    —
                    <a href="/category/foundation">
                        Foundation
                    </a>
                    —
                    <a
                        href="/author/denise-almeida">
                        Denise Almeida
                    </a>
                </span>
                
            </header>
            <div>
                
                <p>We join our voices to technology companies, trade associations and other supporters in asking EU member states to align the Council's position on the CSA Regulation to the position agreed by the Parliament.</p>
<p>Safeguarding encryption should be a priority in negotiations, ensuring the protection of rights and freedoms around privacy and security of communications.</p>
<p>A copy of the open letter sent to ministers can be read below.</p>
<h2 id="open-letter-to-eu-member-states-on-the-proposed-csa-regulation">Open letter to EU Member States on the proposed CSA Regulation</h2>
<p>Dear Ministers of the Interior, Justice, and Economy of EU Member States,</p>
<p>We write to you as small and medium-sized companies and organizations from Europe, concerned about the proposal for a Regulation on Child Sexual Abuse (CSA). Collectively, we call on you to ensure that your country’s position on this file is brought as close as possible to the European Parliament’s (EP) one.
We all agree that ensuring children are safe online is one of the most important duties of tech companies and for this reason, we find the European Commission’s proposed Regulation extremely worrying. If it were implemented as proposed, it would negatively impact children’s privacy and security online, while also having dramatic unforeseen consequences on the EU cybersecurity landscape, on top of creating an ineffective administrative burden<sup class="footnote-reference"><a href="#1">1</a></sup>.
The European Parliament recently adopted its position on the file, acknowledging that scanning technologies are not compatible with the aim of having confidential and secure communications.  The crucial changes it therefore puts forward for the proposal reflect the opinions of the European Data Protection Supervisor (EDPS), the Council legal services as well as countless experts in cryptography and cybersecurity<sup class="footnote-reference"><a href="#2">2</a></sup>. It also reflects the opinion of between 63% and 69% of the companies, public authorities, NGOs and citizens consulted by the European Commission in its Impact Assessment<sup class="footnote-reference"><a href="#3">3</a></sup>.
As small and medium-sized tech companies and organizations, we share their concerns as we know that looking for specific content – such as text, photos and videos – in an end-to-end encrypted communication would require the implementation of a backdoor, or of a similar technology called “client-side scanning”. Even if this mechanism is created with the purpose of fighting crime online, it would also quickly be used by criminals themselves, putting citizens and businesses more at risk online by creating vulnerabilities for all users alike.</p>
<h3 id="data-protection-is-a-strong-competitive-advantage">Data protection is a strong competitive advantage</h3>
<p>As tech companies operating within the European Union, we have built products and services in line with the strong data protection framework of the EU which still serves as an example and inspiration across the world.</p>
<p>The GDPR allowed for the creation of ethical, privacy-first tech companies in Europe, that would otherwise never have been able to compete against Big Tech. It gave European companies a strong competitive advantage in that field internationally and allowed consumers to finally be able to find alternatives to American and Chinese services. Our users, both within the EU and beyond, have come to trust our commitment to safeguarding their data and this trust is a key driver of our competitiveness. The learning curve for adapting to the necessary administrative burden brought about by the GDPR was high but was worth it.
However, the CSA Regulation could threaten this unique selling point of European IT companies and would also add a new administrative burden which we fear could overwhelm both our companies and law enforcement bodies. Considering the volume of communications and content transiting through our services, even an insignificant error rate of the technologies applied to scan for abusive material would result in millions of false positives to be manually reviewed every day.</p>
<h3 id="the-csa-regulation-could-erode-trust-and-safety-online">The CSA Regulation could erode trust and safety online</h3>
<p>In a world where data breaches and privacy scandals are increasingly common, the EU's reputation for stringent data protection is a unique selling point for businesses operating within its borders. It provides us with a competitive edge, assuring our customers that their information is handled with the utmost care and integrity. This trust, once eroded, is challenging to rebuild, and any measures that compromise it such as mandatory scanning, or mandatory age verification have the potential to harm businesses both large and small.
Furthermore, the EU has recently adopted Regulation 2023/2841, which mandates that EU Institutions and bodies to consider the use of end-to-end encryption among their cybersecurity risk-management measures. There are also multiple ‘cyber’ EU proposals currently on the table, such as the Cyber Resilience Act and the Cybersecurity Act. Supporting an opposite approach for the CSA Regulation would only undermine the EU cybersecurity framework creating a contradictory, incoherent and inefficient new set of measures that companies would not be able to enforce without putting citizens and businesses at risk.</p>
<h3 id="the-eu-parliament-s-proposal-goes-in-the-right-direction">The EU Parliament's proposal goes in the right direction</h3>
<p>Therefore, we applaud the European Parliament for its resolute stance in defending the European citizens' right to privacy and secure communication. The European Parliament’s commitment to these principles is not only a testament to its dedication to human rights, but also a beacon of hope for businesses like ours that prioritize data protection and security. The position of the Parliament includes alternatives to scanning which have a minimal impact on cybersecurity and data protection, and which experts believe would be both more effective and more efficient than mandatory scanning. Such changes of paradigm would mean going beyond the false dichotomy between privacy and security, while also making the proposal respect the proportionality principle, as requested by the Regulatory Scrutiny Board.
Even if not perfect in our eyes, the changes the European Parliament made in its position are a good compromise to maintain digital security and confidentiality and to better protect children online. We believe that these changes strike the right balance between child protection and safeguarding privacy and cybersecurity.</p>
<p><strong>As representatives of the vibrant European small businesses community, we encourage EU Member States to continue championing the values of privacy, cybersecurity and data protection. These principles not only align with the EU's commitment to human rights, but also serve as a foundation for a thriving and competitive business environment. Let us defend and strengthen these principles, ensuring that the EU remains an advocate of privacy in the global marketplace.</strong></p>
<p>For these reasons we call on you to:</p>
<ul>
<li>Ensure that Council’s position is aligned as closely as possible to the European Parliament’s. This will allow for a swifter adoption of the Regulation while building on the important work of the European Parliament.</li>
<li>Maintain the high level of fundamental rights - and in particular data protection – enjoyed by citizens in the European Union.</li>
<li>Refrain from forcing companies like us to conduct mass surveillance of private correspondence on behalf of law enforcement agencies.</li>
<li>Guarantee a high level of cybersecurity in the EU by protecting end-to-end encryption and bringing the necessary safeguards in the text. Client-side scanning and backdoors in particular should not be mandated.</li>
<li>Preserve the confidentiality of correspondence.</li>
<li>Minimize the administrative burden of the proposal by making it more effective and efficient, through alternatives to mass scanning.</li>
</ul>
<p>Signed,</p>
<ul>
<li>Blacknight Solutions (Ireland)</li>
<li>Element (United Kingdom)</li>
<li>Mail.de GmbH (Germany)</li>
<li>Matrix Foundation (United Kingdom)</li>
<li>Nextcloud (Germany)</li>
<li>Open-Xchange (Germany)</li>
<li>Renvis (Greece)</li>
<li>TelemetryDeck (Germany)</li>
<li>Tresorit (Switzerland)</li>
<li>E Foundation (France)</li>
<li>Logilab (France)</li>
<li>Mailfence (Belgium)</li>
<li>Murena (France)</li>
<li>Olvid (France)</li>
<li>Proton (Switzerland)</li>
<li>Surfshark (Lithuania)</li>
<li>Threema (Switzerland)</li>
<li>Tuta (Germany)</li>
</ul>
<p>Trade associations and supporters:</p>
<ul>
<li>ACT | The App Association</li>
<li>Defend Democracy</li>
<li>Gate 15</li>
<li>Myntex</li>
<li>Quilibrium</li>
<li>Studio Legale Fabiano</li>
<li>Cyberstorm</li>
<li>Encryption Europe</li>
<li>ISOC-CAT</li>
<li>Privacy &amp; Access Council of Canada</li>
<li>SecureCrypt</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>A detailed summary of the proposal, drafted by the NGO EDRi, is available here: <a href="https://edri.org/our-work/private-and-secure-communications-put-at-risk-by-european-commissions-latest-proposal/">https://edri.org/our-work/private-and-secure-communications-put-at-risk-by-european-commissions-latest-proposal/</a></p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>For more information, you can read their statement from July 2023: <a href="https://edri.org/wp-content/uploads/2023/07/Open-Letter-CSA-Scientific-community.pdf">https://edri.org/wp-content/uploads/2023/07/Open-Letter-CSA-Scientific-community.pdf</a></p>
</div>
<div class="footnote-definition" id="3"><sup class="footnote-definition-label">3</sup>
<p>See in particular page 134 of the impact assessment: <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:52022SC0209">https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:52022SC0209</a></p>
</div>

                
            </div>
        </article>
        
        <article class="post">
            <header>
                <h2><a href="https:&#x2F;&#x2F;tune-your-chat.github.io&#x2F;blog&#x2F;2021&#x2F;05&#x2F;19&#x2F;how-the-uk-s-online-safety-bill-threatens-matrix&#x2F;" title="How the UK&#x27;s Online Safety Bill threatens Matrix">How the UK&#x27;s Online Safety Bill threatens Matrix</a></h2>
                <span>
                    19.05.2021 15:47
                    —
                    <a href="/category/tech">
                        Tech
                    </a>
                    —
                    <a
                        href="/author/denise-almeida">
                        Denise Almeida
                    </a>
                </span>
                <br>
                <small>Last update: 19.05.2021 14:48</small>
            </header>
            <div>
                
                <p>Last week the UK government published a <a href="https://www.gov.uk/government/publications/draft-online-safety-bill">draft of the proposed Online Safety
Bill,</a>
after having initially introduced <a href="https://www.gov.uk/government/consultations/online-harms-white-paper/public-feedback/online-harms-white-paper-initial-consultation-response">formal proposals for said bill in early
2020</a>.
With this post we aim to shed some light on its potential impacts and explain
why we think that this bill - despite having great intentions - may actually
be setting a dangerous precedent when it comes to our rights to privacy,
freedom of expression and self determination.</p>
<p>The proposed bill aims to provide a legal framework to address illegal and
harmful content online. This focus on “not illegal, but harmful” content is at
the centre of our concerns - it puts responsibility on organisations
themselves to arbitrarily decide what might be harmful, without any legal
backing. The bill itself does not actually provide a definition of harmful,
instead relying on service providers to assess and decide on this. This
requirement to identify what is “likely to be harmful” applies to all users,
children and adults. Our question here is - would you trust a service provider
to decide what might be harmful to you and your children, with zero input from
you as a user?</p>
<p>Additionally, the bill incentivises the use of privacy-invasive age
verification processes which come with their own set of problems. This
complete disregard of people’s right to privacy is a reflection of the
privileged perspectives of those in charge of the drafting of this bill, which
fails to acknowledge how <em>actually</em> harmful it would be for certain groups of
the population to have their real life identity associated with their online
identity.</p>
<p>Our view of the world, and of the internet, is largely different from the one
presented by this bill. Now, this categorically does not mean we don’t care
about online safety (it is quite literally our bread and butter) - we just
fundamentally disagree with the approach taken.</p>
<p>Whilst we sympathise with the government’s desire to show action in this space
and to do something about children’s safety (everyone’s safety really), we
cannot possibly agree with the methods.</p>
<p>Back in October of 2020 we presented <a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors">our proposed approach to online safety</a> -
ironically also in response to a government proposal, albeit about encryption
backdoors. In it, we briefly discussed the dangers of absolute determinations
of morality from a single cultural perspective:</p>
<blockquote>
<p><a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors">As uncomfortable as it may be, one man’s terrorist is another man’s freedom fighter, and different jurisdictions have different laws - and it’s not up to the Matrix.org Foundation to play God and adjudicate.</a></p>
</blockquote>
<p>We now find ourselves reading a piece of legislation that essentially demands
these determinations from tech companies. The beauty of the human experience
lies with its diversity and when we force technology companies to make calls
about what is right or wrong - or what is “likely to have adverse
psychological or physical impacts” on children - we end up in a dangerous
place of centralising and regulating relative morals. Worst of all, when the
consequence of getting it wrong is criminal liability for senior managers what
do we think will happen?</p>
<p>Regardless of how omnipresent it is in our daily lives, technology is still
not a solution for human problems. Forcing organisations to be judge and jury
of human morals for the sake of “free speech” will, ironically, have severe
consequences on free speech, as risk profiles will change for fear of
liability.</p>
<p>Forcing a “duty of care” responsibility on organisations which operate online
will not only drown small and medium sized companies in administrative tasks
and costs, it will further accentuate the existing monopolies by Big Tech.
Plainly, Big Tech can afford the regulatory burden - small start-ups can’t.
Future creators will have their wings clipped from the offset and we might
just miss out on new ideas and projects for fear of legal repercussions. This
is a threat to the technology sector, particularly those building on emerging
technologies like Matrix. In some ways, it is a threat to democracy and some
of the freedoms this bill claims to protect.</p>
<p>These are, quite frankly, steps towards an authoritarian dystopia. If Trust &amp;
Safety managers start censoring something as natural as a nipple on the off
chance it might cause “adverse psychological impacts” on children, whose
freedom of expression are we actually protecting here?</p>
<p>More specifically on the issue of content moderation: the <a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/985283/Draft_Online_Safety_Bill_-_Impact_Assessment_Web_Accessible.pdf">impact assessment
provided by the government alongside this
bill</a>
predicts that the additional costs for companies directly related to the bill
will be in the billions, over the course of 10 years. The cost for the
government? £400k, in every proposed policy option. Our question is - why are
these responsibilities being placed on tech companies, when evidently this is
a societal problem?</p>
<p>We are not saying it is up to the government to single-handedly end the
existence of Child Sexual Abuse and Exploitation (CSAE) or extremist content
online. What we are saying is that it takes more than content filtering, risk
assessments and (faulty) age verification processes for it to end. More
funding for tech literacy organisations and schools, to give children (and
parents) the tools to stay safe is the first thing that comes to mind. Further
investment in law enforcement cyber units and the judicial system, improving
tech companies’ routes for abuse reporting and allowing the actual judges to
do the judging seems pretty sensible too. What is absolutely egregious is the
degradation of the digital rights of the majority, due to the wrongdoings of a
few.</p>
<p>Our goal with this post is not to be dramatic or alarmist. However, we want to
add our voices to the countless <a href="https://www.openrightsgroup.org/blog/online-abuse-why-management-liability-isnt-the-answer/">digital rights
campaigners</a>,
individuals and organisations that have been raising the alarm since the early
days of this bill. Just like with coercive control and abuse, the degradation
of our rights does not happen all at once. It is a slippery slope that starts
with something as (seemingly) innocuous as <a href="https://twitter.com/matthew_d_green/status/1392823038920564736">mandatory content scanning for
CSAE content and ends with authoritarian surveillance
infrastructure</a>.
It is our duty to put a stop to this before it even begins.</p>
<small style="display: block; text-align: right">
Twitter card image credit from <a href="https://film-grab.com/2010/10/04/brazil/#bwg644/39614">Brazil</a>, which feels all too familiar right now.
</small>

                
            </div>
        </article>
        
        <nav class="pagination">
    <div class="prev">
        
    </div>
    <span class="page-number">1 / 1</span>
    <div class="prev">
        
    </div>
</nav>

    </div>
</div>

    </main>

    <footer class="site-footer">
    <div class="internal-links">
        
        <a href="&#x2F;support">Donate</a>
        
        <a href="https:&#x2F;&#x2F;shop.matrix.org">Shop</a>
        
        <a href="&#x2F;security-disclosure-policy">Security Disclosure Policy</a>
        
        <a href="&#x2F;security-hall-of-fame">Security Hall of Fame</a>
        
        <a href="&#x2F;legal&#x2F;code-of-conduct">Code of Conduct</a>
        
        <a href="&#x2F;legal">Legal</a>
        
        <a href="&#x2F;contact">Contact</a>
        
        <a href="https:&#x2F;&#x2F;github.com&#x2F;matrix-org&#x2F;matrix.org&#x2F;">Site Source</a>
        
    </div>
    <div class="external-links">
        <div>
            
            <a href="https:&#x2F;&#x2F;github.com&#x2F;matrix-org" rel="me"><img src="/assets/github.svg" alt="GitHub"></a>
            
            <a href="https:&#x2F;&#x2F;gitlab.matrix.org&#x2F;" rel="me"><img src="/assets/gitlab.svg" alt="GitLab"></a>
            
            <a href="https:&#x2F;&#x2F;mastodon.matrix.org&#x2F;@matrix" rel="me"><img src="/assets/mastodon.svg" alt="Mastodon"></a>
            
            <a href="https:&#x2F;&#x2F;twitter.com&#x2F;matrixdotorg" rel="me"><img src="/assets/twitter.svg" alt="Twitter"></a>
            
            <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCVFkW-chclhuyYRbmmfwt6w" rel="me"><img src="/assets/youtube.svg" alt="YouTube"></a>
            
            <a href="&#x2F;atom.xml" rel="me"><img src="/assets/rss.svg" alt="RSS"></a>
            
        </div>
    </div>
    <p><a href="/legal/copyright-notice">Copyright Notice</a></p>
</footer>

</body>

</html>
